{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将一个NLP中的小知识\n",
    "- 如何将一个string转换成一个vector来表示呢？\n",
    "- 方法1：one-hot编码，即每个单词用一个独一无二的one-hot编码来表示，缺点：编码过于稀疏，切断了每个单词之间的联系，比如like,dislike。\n",
    "- 方法2：embedding。很常用的方法，很好，很强大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch中的数据类型的区别\n",
    "比如float类型。torch.float和torch.cuda.float是不一样的，一个在cpu的内存上，而另一个在gpu上，一般来说，在用pytorch进行编程的时候很少显示的用torch.cuda.float，因为有to方法的存在，一切都变得容易了许多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.float32\n",
      "<class 'torch.Tensor'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# type check\n",
    "a = torch.randn(2, 3)\n",
    "print(a.type())\n",
    "print(a.dtype)\n",
    "print(type(a))\n",
    "print(isinstance(a, torch.FloatTensor))\n",
    "# 我的电脑没有GPU啊啊啊。。不支持gpu加速运算\n",
    "if torch.cuda.is_available():\n",
    "    print(isinstance(a, torch.cuda.FloatTensor))\n",
    "    a = a.cuda()\n",
    "    print(isinstance(a, torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "0\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# scalar，比如loss\n",
    "a = torch.tensor(1.)\n",
    "print(a)\n",
    "print(a.dim())  # 注意dim()代表的是Rank，要和size()区分开来\n",
    "print(a.size())\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "1 torch.Size([1]) torch.Size([1])\n",
      "tensor([-4.4716e-35,  3.0707e-41])\n",
      "tensor([1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# vector，比如bias\n",
    "a = torch.tensor([1.])\n",
    "print(a)\n",
    "print(a.dim(), a.size(), a.shape)\n",
    "b = torch.FloatTensor(2) # 此时是一个随机初始化的vector\n",
    "print(b)\n",
    "c = np.ones([2])\n",
    "c_tensor = torch.from_numpy(c)\n",
    "print(c_tensor)\n",
    "# 注意[1.]和1.0的区别，前者是长度为1的vector，后者是一个真正的scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3335,  0.0702, -1.2592],\n",
      "        [-1.7669, -0.8571, -0.2777]])\n",
      "tensor([[-4.4325e-35,  3.0707e-41,  1.4013e-45],\n",
      "        [ 0.0000e+00, -8.5711e-01, -2.7767e-01]])\n",
      "torch.Size([2, 3]) 2 3\n",
      "torch.Size([2, 3]) 2 3\n"
     ]
    }
   ],
   "source": [
    "# dim=2，带有batch的linear层的输入\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "b = torch.FloatTensor(2, 3) # 随机初始化\n",
    "print(b)\n",
    "print(a.size(), a.size(0), a.size(1))\n",
    "print(a.shape,a.shape[0], a.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5293, 0.5398, 0.2651],\n",
      "         [0.1321, 0.5153, 0.0456]]])\n",
      "tensor([[[-1.8866e-35,  3.0707e-41,  1.4013e-45],\n",
      "         [ 0.0000e+00,  1.4013e-45,  0.0000e+00]]])\n",
      "tensor([[0.5293, 0.5398, 0.2651],\n",
      "        [0.1321, 0.5153, 0.0456]])\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# dim=3 RNN input batch\n",
    "# 比如 [10, 20, 100]  20个句子，每个句子有10个单词，每个单词用length=100的vector来表示\n",
    "a = torch.rand(1, 2, 3)\n",
    "print(a)\n",
    "b = torch.FloatTensor(1, 2, 3)\n",
    "print(b)\n",
    "print(a[0]) # a[0]和a很像，注意区别\n",
    "print(list(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([2, 3, 28, 28])\n",
      "4704\n"
     ]
    }
   ],
   "source": [
    "# dim=4 CNN input batch\n",
    "a = torch.rand(2, 3, 28, 28)\n",
    "print(a.dim())\n",
    "print(a.shape)\n",
    "print(a.numel()) # 2*3*28*28"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
